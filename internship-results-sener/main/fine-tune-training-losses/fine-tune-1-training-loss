==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1
   \\   /|    Num examples = 1,462 | Num Epochs = 1
O^O/ \_/ \    Batch size per device = 2 | Gradient Accumulation steps = 4
\        /    Total batch size = 8 | Total steps = 60
 "-____-"     Number of trainable parameters = 41,943,040
 [60/60 11:37, Epoch 0/1]
Step	Training Loss
1	2.181600
2	1.951800
3	2.026800
4	1.741600
5	1.937100
6	1.759100
7	1.870600
8	1.756600
9	1.564600
10	1.381700
11	1.633800
12	1.543400
13	1.523200
14	1.708100
15	1.631300
16	1.279700
17	1.399600
18	1.315900
19	1.562900
20	1.596800
21	1.631500
22	1.407400
23	1.294600
24	1.424600
25	1.439100
26	1.675900
27	1.361200
28	1.109400
29	1.402500
30	1.363600
31	1.195700
32	1.157100
33	1.472900
34	1.408500
35	1.551000
36	1.650800
37	1.464000
38	1.281400
39	1.243500
40	1.343900
41	1.615200
42	1.325000
43	1.458900
44	1.511500
45	1.398600
46	1.486900
47	1.425900
48	1.221000
49	1.637000
50	1.494000
51	1.169700
52	1.380900
53	1.436300
54	1.024100
55	1.282100
56	1.402200
57	1.244700
58	1.336600
59	1.163900
60	1.527000