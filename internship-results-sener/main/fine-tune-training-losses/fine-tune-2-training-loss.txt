==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1
   \\   /|    Num examples = 1,735 | Num Epochs = 1
O^O/ \_/ \    Batch size per device = 2 | Gradient Accumulation steps = 4
\        /    Total batch size = 8 | Total steps = 60
 "-____-"     Number of trainable parameters = 41,943,040
 [60/60 11:56, Epoch 0/1]
Step	Training Loss
1	1.758200
2	1.876500
3	1.800200
4	1.907000
5	1.937800
6	1.734200
7	1.714900
8	1.649000
9	1.616000
10	1.570700
11	1.815500
12	1.401900
13	1.191400
14	1.560300
15	1.325400
16	1.147400
17	1.458900
18	1.467200
19	1.145700
20	1.426900
21	1.323800
22	1.389300
23	1.080600
24	1.038300
25	1.401700
26	1.172400
27	0.862400
28	1.254900
29	1.494600
30	1.260100
31	1.172600
32	1.491500
33	0.997200
34	1.307100
35	1.087500
36	1.326900
37	1.124300
38	1.401300
39	1.270600
40	1.092600
41	0.849700
42	1.467700
43	1.011200
44	1.323500
45	1.220300
46	1.284600
47	0.936900
48	1.181200
49	1.168500
50	1.339000
51	1.501400
52	1.326000
53	1.128300
54	1.216900
55	1.416100
56	1.174300
57	1.032200
58	1.202200
59	1.334100
60	1.022800