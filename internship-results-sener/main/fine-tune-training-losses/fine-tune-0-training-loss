==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1
   \\   /|    Num examples = 765 | Num Epochs = 1
O^O/ \_/ \    Batch size per device = 2 | Gradient Accumulation steps = 4
\        /    Total batch size = 8 | Total steps = 60
 "-____-"     Number of trainable parameters = 41,943,040
 [60/60 09:35, Epoch 0/1]
Step	Training Loss
1	1.687700
2	1.813500
3	1.756900
4	1.890100
5	1.796800
6	1.652400
7	1.445900
8	1.493800
9	1.336200
10	1.406400
11	1.256300
12	1.276500
13	1.285200
14	1.554000
15	1.205200
16	1.142400
17	1.115600
18	1.310800
19	1.154500
20	1.360900
21	1.192800
22	1.253800
23	1.238800
24	1.074600
25	1.182000
26	1.162100
27	1.055300
28	0.965100
29	1.069400
30	0.961900
31	0.919800
32	0.969800
33	1.050600
34	1.145800
35	0.736100
36	0.991200
37	1.086800
38	0.959200
39	1.109100
40	0.810500
41	0.945800
42	0.770500
43	1.129600
44	1.082600
45	0.905700
46	0.779400
47	1.075200
48	0.895800
49	0.805400
50	0.834100
51	0.937000
52	0.689600
53	0.827700
54	0.838800
55	0.795400
56	0.881000
57	0.930200
58	0.838100
59	0.668700
60	0.733000